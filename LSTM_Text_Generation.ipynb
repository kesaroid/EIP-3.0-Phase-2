{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Text Generation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kesaroid/EIP-3.0-Phase-2/blob/master/LSTM_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGx5HeqVrKs0",
        "colab_type": "code",
        "outputId": "5e015a88-a85c-44aa-b85d-9716d9e73ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load Larger LSTM network and generate text\n",
        "import sys\n",
        "import numpy\n",
        "import string\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mzFrxQxwQWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ada16c0c-74ef-4df2-9200-23cd802f6171"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJXx0azCTC98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3573d186-c53e-4279-cc56-4832f3065f12"
      },
      "source": [
        "%cd 'drive/My Drive/EIP'\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/EIP\n",
            "A4  Prisma-esque  wonderland.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv0XbjusrcpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szcFXEOsrop8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_text = raw_text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(clean_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA7DxMWzrpAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0235b7f2-83a8-4f05-8b2e-e14e6cbff28a"
      },
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(clean_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  154861\n",
            "Total Vocab:  39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlKjI7U3rpV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "031b9efc-af75-4076-ab34-583693377004"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = clean_text[i:i + seq_length]\n",
        "\tseq_out = clean_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  154761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE_-YuK8rxvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2CZzxi6rxmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a3a0c833-4468-4414-e280-36c9b9b5a499"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 19:07:52.089005 140436864870272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0820 19:07:52.126985 140436864870272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNVMfPVazgb1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2eb09751-c4cf-42ab-9d2e-db218a5421b7"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=50, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0820 19:07:54.158783 140436864870272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0820 19:07:54.162826 140436864870272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0820 19:07:54.177446 140436864870272 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0820 19:07:54.196263 140436864870272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0820 19:07:54.832529 140436864870272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0820 19:07:54.972038 140436864870272 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "154761/154761 [==============================] - 352s 2ms/step - loss: 2.8015\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.80155, saving model to weights-best.hdf5\n",
            "Epoch 2/50\n",
            "154761/154761 [==============================] - 348s 2ms/step - loss: 2.6094\n",
            "\n",
            "Epoch 00002: loss improved from 2.80155 to 2.60939, saving model to weights-best.hdf5\n",
            "Epoch 3/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 2.4449\n",
            "\n",
            "Epoch 00003: loss improved from 2.60939 to 2.44493, saving model to weights-best.hdf5\n",
            "Epoch 4/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 2.3285\n",
            "\n",
            "Epoch 00004: loss improved from 2.44493 to 2.32855, saving model to weights-best.hdf5\n",
            "Epoch 5/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 2.2445\n",
            "\n",
            "Epoch 00005: loss improved from 2.32855 to 2.24451, saving model to weights-best.hdf5\n",
            "Epoch 6/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 2.1782\n",
            "\n",
            "Epoch 00006: loss improved from 2.24451 to 2.17819, saving model to weights-best.hdf5\n",
            "Epoch 7/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 2.1181\n",
            "\n",
            "Epoch 00007: loss improved from 2.17819 to 2.11811, saving model to weights-best.hdf5\n",
            "Epoch 8/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 2.0677\n",
            "\n",
            "Epoch 00008: loss improved from 2.11811 to 2.06774, saving model to weights-best.hdf5\n",
            "Epoch 9/50\n",
            "154761/154761 [==============================] - 348s 2ms/step - loss: 2.0543\n",
            "\n",
            "Epoch 00009: loss improved from 2.06774 to 2.05428, saving model to weights-best.hdf5\n",
            "Epoch 10/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.9891\n",
            "\n",
            "Epoch 00010: loss improved from 2.05428 to 1.98909, saving model to weights-best.hdf5\n",
            "Epoch 11/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.9560\n",
            "\n",
            "Epoch 00011: loss improved from 1.98909 to 1.95605, saving model to weights-best.hdf5\n",
            "Epoch 12/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.9203\n",
            "\n",
            "Epoch 00012: loss improved from 1.95605 to 1.92027, saving model to weights-best.hdf5\n",
            "Epoch 13/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.8938\n",
            "\n",
            "Epoch 00013: loss improved from 1.92027 to 1.89376, saving model to weights-best.hdf5\n",
            "Epoch 14/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.8729\n",
            "\n",
            "Epoch 00014: loss improved from 1.89376 to 1.87286, saving model to weights-best.hdf5\n",
            "Epoch 15/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.8410\n",
            "\n",
            "Epoch 00015: loss improved from 1.87286 to 1.84096, saving model to weights-best.hdf5\n",
            "Epoch 16/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.8210\n",
            "\n",
            "Epoch 00016: loss improved from 1.84096 to 1.82105, saving model to weights-best.hdf5\n",
            "Epoch 17/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.8022\n",
            "\n",
            "Epoch 00017: loss improved from 1.82105 to 1.80221, saving model to weights-best.hdf5\n",
            "Epoch 18/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 1.7831\n",
            "\n",
            "Epoch 00018: loss improved from 1.80221 to 1.78306, saving model to weights-best.hdf5\n",
            "Epoch 19/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 1.7636\n",
            "\n",
            "Epoch 00019: loss improved from 1.78306 to 1.76360, saving model to weights-best.hdf5\n",
            "Epoch 20/50\n",
            "154761/154761 [==============================] - 352s 2ms/step - loss: 1.7482\n",
            "\n",
            "Epoch 00020: loss improved from 1.76360 to 1.74815, saving model to weights-best.hdf5\n",
            "Epoch 21/50\n",
            "154761/154761 [==============================] - 344s 2ms/step - loss: 1.7307\n",
            "\n",
            "Epoch 00021: loss improved from 1.74815 to 1.73067, saving model to weights-best.hdf5\n",
            "Epoch 22/50\n",
            "154761/154761 [==============================] - 344s 2ms/step - loss: 1.7139\n",
            "\n",
            "Epoch 00022: loss improved from 1.73067 to 1.71391, saving model to weights-best.hdf5\n",
            "Epoch 23/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.7021\n",
            "\n",
            "Epoch 00023: loss improved from 1.71391 to 1.70214, saving model to weights-best.hdf5\n",
            "Epoch 24/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.6858\n",
            "\n",
            "Epoch 00024: loss improved from 1.70214 to 1.68584, saving model to weights-best.hdf5\n",
            "Epoch 25/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.6760\n",
            "\n",
            "Epoch 00025: loss improved from 1.68584 to 1.67596, saving model to weights-best.hdf5\n",
            "Epoch 26/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.6643\n",
            "\n",
            "Epoch 00026: loss improved from 1.67596 to 1.66435, saving model to weights-best.hdf5\n",
            "Epoch 27/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.6467\n",
            "\n",
            "Epoch 00027: loss improved from 1.66435 to 1.64670, saving model to weights-best.hdf5\n",
            "Epoch 28/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 1.6377\n",
            "\n",
            "Epoch 00028: loss improved from 1.64670 to 1.63765, saving model to weights-best.hdf5\n",
            "Epoch 29/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.6275\n",
            "\n",
            "Epoch 00029: loss improved from 1.63765 to 1.62752, saving model to weights-best.hdf5\n",
            "Epoch 30/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.6208\n",
            "\n",
            "Epoch 00030: loss improved from 1.62752 to 1.62076, saving model to weights-best.hdf5\n",
            "Epoch 31/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.6068\n",
            "\n",
            "Epoch 00031: loss improved from 1.62076 to 1.60682, saving model to weights-best.hdf5\n",
            "Epoch 32/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.6029\n",
            "\n",
            "Epoch 00032: loss improved from 1.60682 to 1.60288, saving model to weights-best.hdf5\n",
            "Epoch 33/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.5902\n",
            "\n",
            "Epoch 00033: loss improved from 1.60288 to 1.59024, saving model to weights-best.hdf5\n",
            "Epoch 34/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.5847\n",
            "\n",
            "Epoch 00034: loss improved from 1.59024 to 1.58466, saving model to weights-best.hdf5\n",
            "Epoch 35/50\n",
            "154761/154761 [==============================] - 344s 2ms/step - loss: 1.5727\n",
            "\n",
            "Epoch 00035: loss improved from 1.58466 to 1.57271, saving model to weights-best.hdf5\n",
            "Epoch 36/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.5660\n",
            "\n",
            "Epoch 00036: loss improved from 1.57271 to 1.56604, saving model to weights-best.hdf5\n",
            "Epoch 37/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.5656\n",
            "\n",
            "Epoch 00037: loss improved from 1.56604 to 1.56557, saving model to weights-best.hdf5\n",
            "Epoch 38/50\n",
            "154761/154761 [==============================] - 348s 2ms/step - loss: 1.5533\n",
            "\n",
            "Epoch 00038: loss improved from 1.56557 to 1.55325, saving model to weights-best.hdf5\n",
            "Epoch 39/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 1.5458\n",
            "\n",
            "Epoch 00039: loss improved from 1.55325 to 1.54578, saving model to weights-best.hdf5\n",
            "Epoch 40/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.5395\n",
            "\n",
            "Epoch 00040: loss improved from 1.54578 to 1.53947, saving model to weights-best.hdf5\n",
            "Epoch 41/50\n",
            "154761/154761 [==============================] - 349s 2ms/step - loss: 1.5363\n",
            "\n",
            "Epoch 00041: loss improved from 1.53947 to 1.53629, saving model to weights-best.hdf5\n",
            "Epoch 42/50\n",
            "154761/154761 [==============================] - 347s 2ms/step - loss: 1.5246\n",
            "\n",
            "Epoch 00042: loss improved from 1.53629 to 1.52457, saving model to weights-best.hdf5\n",
            "Epoch 43/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.5260\n",
            "\n",
            "Epoch 00043: loss did not improve from 1.52457\n",
            "Epoch 44/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.5206\n",
            "\n",
            "Epoch 00044: loss improved from 1.52457 to 1.52065, saving model to weights-best.hdf5\n",
            "Epoch 45/50\n",
            "154761/154761 [==============================] - 344s 2ms/step - loss: 1.5165\n",
            "\n",
            "Epoch 00045: loss improved from 1.52065 to 1.51649, saving model to weights-best.hdf5\n",
            "Epoch 46/50\n",
            "154761/154761 [==============================] - 346s 2ms/step - loss: 1.5042\n",
            "\n",
            "Epoch 00046: loss improved from 1.51649 to 1.50421, saving model to weights-best.hdf5\n",
            "Epoch 47/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.5051\n",
            "\n",
            "Epoch 00047: loss did not improve from 1.50421\n",
            "Epoch 48/50\n",
            "154761/154761 [==============================] - 345s 2ms/step - loss: 1.4962\n",
            "\n",
            "Epoch 00048: loss improved from 1.50421 to 1.49620, saving model to weights-best.hdf5\n",
            "Epoch 49/50\n",
            "154761/154761 [==============================] - 344s 2ms/step - loss: 1.4882\n",
            "\n",
            "Epoch 00049: loss improved from 1.49620 to 1.48821, saving model to weights-best.hdf5\n",
            "Epoch 50/50\n",
            "154761/154761 [==============================] - 343s 2ms/step - loss: 1.4858\n",
            "\n",
            "Epoch 00050: loss improved from 1.48821 to 1.48584, saving model to weights-best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9b7616d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsJEphG1rxcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "78765bc5-44f3-448d-ecf2-760113b1ed8e"
      },
      "source": [
        "# load the network weights\n",
        "filename = \"weights-best.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" ittle way forwards each time and a long way back and barking hoarsely\n",
            "all the while till at last it  \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khNV7mpOrxRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3b74a710-6c4e-45cb-9e27-26fb2b7009ba"
      },
      "source": [
        "# generate characters\n",
        "for i in range(501):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu anlce tuoeieu \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}